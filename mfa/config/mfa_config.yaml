beam: 200
retry_beam: 800

features:
        type: "mfcc"
        use_energy: false
        use_pitch: true
        frame_shift: 5

training:
        - monophone:
                  subset: 10000
                  num_iterations: 5
                  max_gaussians: 1000
                  boost_silence: 1.25

        - triphone:
                  subset: 20000
                  num_iterations: 5
                  num_leaves: 2000
                  max_gaussians: 10000
                  cluster_threshold: -1
                  boost_silence: 1.25
                  power: 0.25
        - lda:
                  subset: 20000
                  num_leaves: 2500
                  max_gaussians: 15000
                  num_iterations: 5
                  features:
                          splice_left_context: 3
                          splice_right_context: 3
# - sat:
#       num_iterations: 1
#       subset: 50000
#       num_leaves: 4200
#       max_gaussians: 40000
#       power: 0.2
#       silence_weight: 0.0
#       fmllr_update_type: "full"

# - pronunciation_probabilities:
#       num_iterations: 1
#       subset: 50000
#       silence_probabilities: true
# - sat:
#       num_iterations: 1
#       subset: 150000
#       num_leaves: 5000
#       max_gaussians: 100000
#       power: 0.2
#       silence_weight: 0.0
#       fmllr_update_type: "full"

# - pronunciation_probabilities:
#       num_iterations: 1
#       subset: 150000
#       silence_probabilities: true
#       optional: true # Skipped if the corpus is smaller than the subset

# - sat:
#       subset: 0
#       quick: true # Performs fewer fMLLR estimation
#       num_iterations: 1
#       num_leaves: 7000
#       max_gaussians: 150000
#       power: 0.2
#       silence_weight: 0.0
#       fmllr_update_type: "full"
#       optional: true # Skipped if the corpus is smaller than the previous subset
