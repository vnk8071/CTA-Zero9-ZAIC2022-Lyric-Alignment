{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 744
        },
        "id": "2-_iYun5T_pr",
        "outputId": "0830bf65-69cb-455d-b568-7e59ef296968"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers==4.20.0\n",
        "# !pip install https://github.com/kpu/kenlm/archive/master.zip\n",
        "# !pip install pyctcdecode==v0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jqJtw42UTYku"
      },
      "outputs": [],
      "source": [
        "from transformers.file_utils import cached_path, hf_bucket_url\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC, AutoTokenizer, Wav2Vec2ProcessorWithLM\n",
        "import librosa\n",
        "import torch\n",
        "import numpy as np\n",
        "import re\n",
        "import json\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from importlib.machinery import SourceFileLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "b2b2ec13a6834f23ad4a35d30d617715",
            "1e3e36e6b9df40f5bd205a2b420db420",
            "27ced834c5e44d1fb669fed14071552f",
            "056aaa65e381432eb38b97360fc3e7f8",
            "961ba4e2036e40288b282c4fd638f44c",
            "1ae1cfc76b6848f5b3ada1411b822df3",
            "a084868d31ca471aaa1bf3fa378b0ce1",
            "ec15220cf3614873919e18849a50d6c3",
            "ddf112e93468493e82e71743a8371371",
            "2cb06fb9347e4ea1a40d8ad765736423",
            "ef53ebb02c8c4d73a551098328e6bfa4"
          ]
        },
        "id": "mMmq5q_rT28L",
        "outputId": "8bed3746-4bea-4664-ba31-c84cf755d2bd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: 100%|██████████| 263/263 [00:00<00:00, 87.8kB/s]\n",
            "Downloading: 100%|██████████| 1.14k/1.14k [00:00<00:00, 293kB/s]\n",
            "Downloading: 100%|██████████| 396/396 [00:00<00:00, 56.6kB/s]\n",
            "Downloading: 100%|██████████| 30.0/30.0 [00:00<00:00, 30.0kB/s]\n",
            "Downloading: 100%|██████████| 2.53k/2.53k [00:00<00:00, 1.30MB/s]\n",
            "c:\\Users\\admin\\anaconda3\\envs\\vnese-wav2vec\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:97: FutureWarning: Deprecated argument(s) used in 'snapshot_download': allow_regex. Will not be supported from version '0.12'.\n",
            "\n",
            "Please use `allow_patterns` and `ignore_patterns` instead.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "Downloading: 100%|██████████| 863/863 [00:00<00:00, 216kB/s]\n",
            "c:\\Users\\admin\\anaconda3\\envs\\vnese-wav2vec\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\pyctcdecode. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Downloading: 100%|██████████| 78.0/78.0 [00:00<00:00, 13.0kB/s]\n",
            "Downloading: 0.00B [00:00, ?B/s] | 2/4 [00:05<00:05,  2.51s/it]\n",
            "Downloading: 100%|██████████| 2.47G/2.47G [24:21<00:00, 1.69MB/s]\n",
            "Fetching 4 files: 100%|██████████| 4/4 [24:32<00:00, 368.10s/it]\n",
            "Only 0 unigrams passed as vocabulary. Is this small or artificial data?\n",
            "Downloading: 100%|██████████| 6.61k/6.61k [00:00<00:00, 51.3kB/s]\n",
            "Downloading: 100%|██████████| 2.23k/2.23k [00:00<00:00, 762kB/s]\n",
            "Downloading: 100%|██████████| 1.19G/1.19G [12:31<00:00, 1.70MB/s] \n"
          ]
        }
      ],
      "source": [
        "model_name = \"nguyenvulebinh/wav2vec2-large-vi-vlsp2020\" # \"nguyenvulebinh/wav2vec2-base-vietnamese-250h\"\n",
        "processor = Wav2Vec2ProcessorWithLM.from_pretrained(model_name)\n",
        "# model = Wav2Vec2ForCTC.from_pretrained(model_name)\n",
        "model = SourceFileLoader(\"model\", cached_path(hf_bucket_url(model_name,filename=\"model_handling.py\"))).load_module().Wav2Vec2ForCTC.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mIt7VrYmUl-m"
      },
      "outputs": [],
      "source": [
        "wav, _ = librosa.load(\"./37303134325f3137.wav\", sr = 16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCAu6UgaTvL7",
        "outputId": "4f3034fb-20f5-4949-a775-f31ee2dd93f0"
      },
      "outputs": [],
      "source": [
        "input_values = processor.feature_extractor(wav, sampling_rate=16000, return_tensors=\"pt\")\n",
        "output = model(**input_values)\n",
        "\n",
        "logits = model(**input_values).logits[0]\n",
        "pred_ids = torch.argmax(logits, axis=-1)\n",
        "pred_transcript = processor.tokenizer.decode(pred_ids)\n",
        "print(f\"transcript: {pred_transcript}\")\n",
        "\n",
        "time_offset = model.config.inputs_to_logits_ratio / 16000\n",
        "\n",
        "outputs = processor.tokenizer.decode(pred_ids, output_word_offsets=True)\n",
        "lyric_offset = [\n",
        "    {\n",
        "        \"Label\": d[\"word\"],\n",
        "        \"Begin\": int(d[\"start_offset\"] * time_offset * 1000),\n",
        "        \"End\": int(d[\"end_offset\"] * time_offset * 1000),\n",
        "}\n",
        "    for d in outputs.word_offsets\n",
        "]\n",
        "print(lyric_offset)\n",
        "print(processor.decode(output.logits.cpu().detach().numpy()[0], beam_width=100).text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "7rLA3RPviBpm",
        "outputId": "7844d7c1-4d82-4429-96c4-f69ce2c7a8c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at nguyenvulebinh/wav2vec2-large-vi were not used when initializing Wav2Vec2ForCTC: ['quantizer.weight_proj.weight', 'quantizer.weight_proj.bias', 'project_q.weight', 'project_hid.weight', 'quantizer.codevectors', 'project_q.bias', 'project_hid.bias']\n",
            "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at nguyenvulebinh/wav2vec2-large-vi and are newly initialized: ['lm_head.weight', 'lm_head.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "ename": "EntryNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEntryNotFoundError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-6be612467698>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWav2Vec2ForCTC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nguyenvulebinh/wav2vec2-large-vi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mlm_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhf_bucket_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nguyenvulebinh/wav2vec2-base-vi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vi_lm_4grams.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlm_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         )\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m             \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0;31m# We favor a custom header indicating the etag of the linked resource, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_raise_for_status\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"404 Client Error: Repository Not Found for url: {response.url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"EntryNotFound\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mEntryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"404 Client Error: Entry Not Found for url: {response.url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"RevisionNotFound\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRevisionNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"404 Client Error: Revision Not Found for url: {response.url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mEntryNotFoundError\u001b[0m: 404 Client Error: Entry Not Found for url: https://huggingface.co/nguyenvulebinh/wav2vec2-base-vi/resolve/main/vi_lm_4grams.bin"
          ]
        }
      ],
      "source": [
        "from transformers.file_utils import cached_path, hf_bucket_url\n",
        "import os, zipfile\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "import torch\n",
        "import kenlm\n",
        "from pyctcdecode import Alphabet, BeamSearchDecoderCTC, LanguageModel\n",
        "import IPython\n",
        "cache_dir = './cache/'\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"nguyenvulebinh/wav2vec2-large-vi\", cache_dir=cache_dir)\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\"nguyenvulebinh/wav2vec2-large-vi\", cache_dir=cache_dir)\n",
        "lm_file = hf_bucket_url(\"nguyenvulebinh/wav2vec2-base-vi\", filename='vi_lm_4grams.bin')\n",
        "lm_file = cached_path(lm_file,cache_dir=cache_dir)\n",
        "with zipfile.ZipFile(lm_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(cache_dir)\n",
        "lm_file = cache_dir + 'vi_lm_4grams.bin'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Kw3AXY7vLIl",
        "outputId": "ae89fba5-c83d-4480-b2f8-b415ead8d2db"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:pyctcdecode.language_model:No known unigrams provided, decoding results might be a lot worse.\n"
          ]
        }
      ],
      "source": [
        "def get_decoder_ngram_model(tokenizer, ngram_lm_path):\n",
        "    vocab_dict = tokenizer.get_vocab()\n",
        "    sort_vocab = sorted((value, key) for (key, value) in vocab_dict.items())\n",
        "    vocab = [x[1] for x in sort_vocab][:-2]\n",
        "    vocab_list = vocab\n",
        "    # convert ctc blank character representation\n",
        "    #vocab_list[tokenizer.pad_token_id] = \"\"\n",
        "    # replace special characters\n",
        "    vocab_list[tokenizer.unk_token_id] = \"\"\n",
        "    # vocab_list[tokenizer.bos_token_id] = \"\"\n",
        "    # vocab_list[tokenizer.eos_token_id] = \"\"\n",
        "    # convert space character representation\n",
        "    vocab_list[tokenizer.word_delimiter_token_id] = \" \"\n",
        "    # specify ctc blank char index, since conventially it is the last entry of the logit matrix\n",
        "    alphabet = Alphabet.build_alphabet(vocab_list)#, ctc_token_idx=tokenizer.pad_token_id)\n",
        "    lm_model = kenlm.Model(ngram_lm_path)\n",
        "    decoder = BeamSearchDecoderCTC(alphabet,\n",
        "                                   language_model=LanguageModel(lm_model))\n",
        "    return decoder\n",
        "ngram_lm_model = get_decoder_ngram_model(processor.tokenizer, lm_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327
        },
        "id": "I5blfNp2vOnL",
        "outputId": "b57e9c69-d38a-4988-9349-80d82923c50b"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2d0057b3a68a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbeam_search_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngram_lm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Beam search output: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeam_search_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyctcdecode/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, logits, beam_width, beam_prune_logp, token_min_logp, hotwords, hotword_weight, lm_start_state)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0mhotwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhotwords\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mhotword_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhotword_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0mlm_start_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlm_start_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         )\n\u001b[1;32m    689\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded_beams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyctcdecode/decoder.py\u001b[0m in \u001b[0;36mdecode_beams\u001b[0;34m(self, logits, beam_width, beam_prune_logp, token_min_logp, prune_history, hotwords, hotword_weight, lm_start_state)\u001b[0m\n\u001b[1;32m    547\u001b[0m             \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mbeams\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mOUTPUT_BEAM\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mvarious\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \"\"\"\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_logits_dimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0;31m# prepare hotword input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0mhotword_scorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHotwordScorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhotwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhotword_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyctcdecode/decoder.py\u001b[0m in \u001b[0;36m_check_logits_dimension\u001b[0;34m(self, logits)\u001b[0m\n\u001b[1;32m    271\u001b[0m             raise ValueError(\n\u001b[1;32m    272\u001b[0m                 \u001b[0;34m\"Input logits shape is %s, but vocabulary is size %s. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0;34m\"Need logits of shape: (time, vocabulary)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_idx2vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             )\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input logits shape is (922, 98), but vocabulary is size 96. Need logits of shape: (time, vocabulary)"
          ]
        }
      ],
      "source": [
        "beam_search_output = ngram_lm_model.decode(logits.cpu().detach().numpy(), beam_width=500)\n",
        "print(\"Beam search output: {}\".format(beam_search_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTm3jIlQwLFa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('vnese-wav2vec')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "ab22c2ad4005729808152da68e6849bb34cd2d938f908e4d98e5900016825120"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "056aaa65e381432eb38b97360fc3e7f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cb06fb9347e4ea1a40d8ad765736423",
            "placeholder": "​",
            "style": "IPY_MODEL_ef53ebb02c8c4d73a551098328e6bfa4",
            "value": " 4/4 [00:00&lt;00:00,  6.94it/s]"
          }
        },
        "1ae1cfc76b6848f5b3ada1411b822df3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e3e36e6b9df40f5bd205a2b420db420": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ae1cfc76b6848f5b3ada1411b822df3",
            "placeholder": "​",
            "style": "IPY_MODEL_a084868d31ca471aaa1bf3fa378b0ce1",
            "value": "Fetching 4 files: 100%"
          }
        },
        "27ced834c5e44d1fb669fed14071552f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec15220cf3614873919e18849a50d6c3",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddf112e93468493e82e71743a8371371",
            "value": 4
          }
        },
        "2cb06fb9347e4ea1a40d8ad765736423": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961ba4e2036e40288b282c4fd638f44c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a084868d31ca471aaa1bf3fa378b0ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2b2ec13a6834f23ad4a35d30d617715": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e3e36e6b9df40f5bd205a2b420db420",
              "IPY_MODEL_27ced834c5e44d1fb669fed14071552f",
              "IPY_MODEL_056aaa65e381432eb38b97360fc3e7f8"
            ],
            "layout": "IPY_MODEL_961ba4e2036e40288b282c4fd638f44c"
          }
        },
        "ddf112e93468493e82e71743a8371371": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec15220cf3614873919e18849a50d6c3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef53ebb02c8c4d73a551098328e6bfa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
