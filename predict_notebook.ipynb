{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  public_test_sample.zip\n",
      "  inflating: data/public_test/json_labels/37303234365f3231.json  \n",
      "  inflating: data/public_test/json_labels/37303234365f3431.json  \n",
      "  inflating: data/public_test/json_labels/37303234365f3732.json  \n",
      "  inflating: data/public_test/labels/37303234365f3231.txt  \n",
      "  inflating: data/public_test/labels/37303234365f3431.txt  \n",
      " extracting: data/public_test/labels/37303234365f3732.txt  \n",
      "  inflating: data/public_test/songs/37303234365f3231.wav  \n",
      "  inflating: data/public_test/songs/37303234365f3431.wav  \n",
      "  inflating: data/public_test/songs/37303234365f3732.wav  \n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!unzip public_test_sample.zip -d data/public_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vnk/miniconda3/envs/lyric-test/lib/python3.8/site-packages/Bio/pairwise2.py:278: BiopythonDeprecationWarning: Bio.pairwise2 has been deprecated, and we intend to remove it in a future release of Biopython. As an alternative, please consider using Bio.Align.PairwiseAligner as a replacement, and contact the Biopython developers if you still need the Bio.pairwise2 module.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "from time import time\n",
    "from utils.process_label_to_txt import convert_txt\n",
    "from demucs_utils.seperate_vocal import separate\n",
    "from mfa.align import create_parser, run_align_corpus\n",
    "from mfa.src.postprocessing import post_process_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBLIC_TEST = \"data/public_test\"\n",
    "SONG_RAW_DIR = \"data/public_test/songs\"\n",
    "RAW_LYRIC_JSON = \"data/public_test/json_labels\"\n",
    "\n",
    "SEPARATED_DATA_DIR = \"data/output\"\n",
    "PUBLIC_TEST_OUTPUT_RAW = \"data/output/public_test_raw\"\n",
    "OUTPUT_DIR = \"data/output/public_test_json\"\n",
    "DICTIONARY_PATH = \"mfa/models/vietnamese_mfa_dict_ver3.dict\"\n",
    "ACOUSTIC_MODEL_PATH = \"mfa/models/mfa_vn_vocal_train_combine_train_public_test.zip\"\n",
    "\n",
    "SUBMISSION_DIR = \"./result\"\n",
    "OUTPUT_FILE = \"./result/submission.zip\"\n",
    "OUTPUT_TIME_SUBMISSION = \"./result/time_submission.csv\"\n",
    "OUTPUT_JUPYTER_FILE = \"./result/jupyter_submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cases = os.listdir(SONG_RAW_DIR)\n",
    "len(test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separate audio: data/public_test/songs/37303234365f3231.wav\n",
      "With command:  python -m demucs.separate -o data/output -n mdx_extra_q -j 2 --float32 --two-stems=vocals\n",
      "Selected model is a bag of 4 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in /mnt/c/Users/Modern 14/projects/CTA-Zero9-ZAIC2022-Lyric-Alignment/data/output/mdx_extra_q\n",
      "Separating track data/public_test/songs/37303234365f3231.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:18<00:00,  1.81seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:16<00:00,  1.95seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:14<00:00,  2.30seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:15<00:00,  2.13seconds/s]\n",
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 10.4.0 (conda-forge gcc 10.4.0-18)\n",
      "  configuration: --prefix=/home/vnk/miniconda3/envs/lyric-test --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : stereo\n",
      "Input #0, wav, from 'data/output/mdx_extra_q/37303234365f3231/vocals.wav':\n",
      "  Duration: 00:00:18.29, bitrate: 2822 kb/s\n",
      "  Stream #0:0: Audio: pcm_f32le ([3][0][0][0] / 0x0003), 44100 Hz, stereo, flt, 2822 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_f32le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'data/output/mdx_extra_q/37303234365f3231/37303234365f3231/37303234365f3231.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf59.27.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 pcm_s16le\n",
      "size=     572kB time=00:00:18.28 bitrate= 256.0kbits/s speed= 292x    \n",
      "video:0kB audio:572kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.013328%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Setting up corpus information...\n",
      "\u001b[32mINFO\u001b[0m - Loading corpus from source files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Found 1 speaker across 1 file, average number of utterances per speaker: 1.0\n",
      "\u001b[32mINFO\u001b[0m - Initializing multiprocessing jobs...\n",
      "\u001b[33mWARNING\u001b[0m - Number of jobs was specified as 3, but due to only having 1 speakers, MFA will only use 1 jobs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Creating corpus split for feature generation...\n",
      "\u001b[32mINFO\u001b[0m - Generating base features (mfcc)...\n",
      "\u001b[32mINFO\u001b[0m - Generating MFCCs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Calculating CMVN...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Creating corpus split with features...\n",
      "\u001b[32mINFO\u001b[0m - Compiling training graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Performing first-pass alignment...\n",
      "\u001b[32mINFO\u001b[0m - Generating alignments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Calculating fMLLR for speaker adaptation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Performing second-pass alignment...\n",
      "\u001b[32mINFO\u001b[0m - Generating alignments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:02<00:00,  3.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Exporting TextGrids to data/output/public_test_raw...\n",
      "\u001b[32mINFO\u001b[0m - Collecting phone and word alignments from alignment lattices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 23.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Finished exporting TextGrids to data/output/public_test_raw!\n",
      "\u001b[32mINFO\u001b[0m - Done! Everything took 27.046233892440796 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separate audio: data/public_test/songs/37303234365f3431.wav\n",
      "With command:  python -m demucs.separate -o data/output -n mdx_extra_q -j 2 --float32 --two-stems=vocals\n",
      "Selected model is a bag of 4 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in /mnt/c/Users/Modern 14/projects/CTA-Zero9-ZAIC2022-Lyric-Alignment/data/output/mdx_extra_q\n",
      "Separating track data/public_test/songs/37303234365f3431.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:28<00:00,  1.16seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:31<00:00,  1.06seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:54<00:00,  1.67s/seconds]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:52<00:00,  1.59s/seconds]\n",
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 10.4.0 (conda-forge gcc 10.4.0-18)\n",
      "  configuration: --prefix=/home/vnk/miniconda3/envs/lyric-test --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : stereo\n",
      "Input #0, wav, from 'data/output/mdx_extra_q/37303234365f3431/vocals.wav':\n",
      "  Duration: 00:00:28.05, bitrate: 2822 kb/s\n",
      "  Stream #0:0: Audio: pcm_f32le ([3][0][0][0] / 0x0003), 44100 Hz, stereo, flt, 2822 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_f32le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'data/output/mdx_extra_q/37303234365f3431/37303234365f3431/37303234365f3431.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf59.27.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 pcm_s16le\n",
      "size=     877kB time=00:00:28.04 bitrate= 256.0kbits/s speed=49.5x        \n",
      "video:0kB audio:876kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.008690%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Setting up corpus information...\n",
      "\u001b[32mINFO\u001b[0m - Loading corpus from source files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Found 1 speaker across 1 file, average number of utterances per speaker: 1.0\n",
      "\u001b[32mINFO\u001b[0m - Initializing multiprocessing jobs...\n",
      "\u001b[33mWARNING\u001b[0m - Number of jobs was specified as 3, but due to only having 1 speakers, MFA will only use 1 jobs.\n",
      "\u001b[32mINFO\u001b[0m - Creating corpus split for feature generation...\n",
      "\u001b[32mINFO\u001b[0m - Generating base features (mfcc)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Generating MFCCs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Calculating CMVN...\n",
      "\u001b[32mINFO\u001b[0m - Creating corpus split with features...\n",
      "\u001b[32mINFO\u001b[0m - Compiling training graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Performing first-pass alignment...\n",
      "\u001b[32mINFO\u001b[0m - Generating alignments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:09<00:00,  9.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Calculating fMLLR for speaker adaptation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Performing second-pass alignment...\n",
      "\u001b[32mINFO\u001b[0m - Generating alignments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:04<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Exporting TextGrids to data/output/public_test_raw...\n",
      "\u001b[32mINFO\u001b[0m - Collecting phone and word alignments from alignment lattices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 16.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Finished exporting TextGrids to data/output/public_test_raw!\n",
      "\u001b[32mINFO\u001b[0m - Done! Everything took 52.5624635219574 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separate audio: data/public_test/songs/37303234365f3732.wav\n",
      "With command:  python -m demucs.separate -o data/output -n mdx_extra_q -j 2 --float32 --two-stems=vocals\n",
      "Selected model is a bag of 4 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in /mnt/c/Users/Modern 14/projects/CTA-Zero9-ZAIC2022-Lyric-Alignment/data/output/mdx_extra_q\n",
      "Separating track data/public_test/songs/37303234365f3732.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:12<00:00,  2.71seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:11<00:00,  2.80seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:20<00:00,  1.63seconds/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 33.0/33.0 [00:17<00:00,  1.84seconds/s]\n",
      "ffmpeg version 5.1.2 Copyright (c) 2000-2022 the FFmpeg developers\n",
      "  built with gcc 10.4.0 (conda-forge gcc 10.4.0-18)\n",
      "  configuration: --prefix=/home/vnk/miniconda3/envs/lyric-test --cc=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-cc --cxx=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-c++ --nm=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-nm --ar=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/x86_64-conda-linux-gnu-ar --disable-doc --disable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libfontconfig --enable-libopenh264 --enable-gnutls --enable-libmp3lame --enable-libvpx --enable-pthreads --enable-vaapi --enable-gpl --enable-libx264 --enable-libx265 --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --pkg-config=/home/conda/feedstock_root/build_artifacts/ffmpeg_1666357487580/_build_env/bin/pkg-config\n",
      "  libavutil      57. 28.100 / 57. 28.100\n",
      "  libavcodec     59. 37.100 / 59. 37.100\n",
      "  libavformat    59. 27.100 / 59. 27.100\n",
      "  libavdevice    59.  7.100 / 59.  7.100\n",
      "  libavfilter     8. 44.100 /  8. 44.100\n",
      "  libswscale      6.  7.100 /  6.  7.100\n",
      "  libswresample   4.  7.100 /  4.  7.100\n",
      "  libpostproc    56.  6.100 / 56.  6.100\n",
      "Guessed Channel Layout for Input Stream #0.0 : stereo\n",
      "Input #0, wav, from 'data/output/mdx_extra_q/37303234365f3732/vocals.wav':\n",
      "  Duration: 00:00:10.79, bitrate: 2822 kb/s\n",
      "  Stream #0:0: Audio: pcm_f32le ([3][0][0][0] / 0x0003), 44100 Hz, stereo, flt, 2822 kb/s\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (pcm_f32le (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to 'data/output/mdx_extra_q/37303234365f3732/37303234365f3732/37303234365f3732.wav':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf59.27.100\n",
      "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
      "    Metadata:\n",
      "      encoder         : Lavc59.37.100 pcm_s16le\n",
      "size=     337kB time=00:00:10.78 bitrate= 256.1kbits/s speed=40.9x        \n",
      "video:0kB audio:337kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.022597%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Setting up corpus information...\n",
      "\u001b[32mINFO\u001b[0m - Loading corpus from source files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Found 1 speaker across 1 file, average number of utterances per speaker: 1.0\n",
      "\u001b[32mINFO\u001b[0m - Initializing multiprocessing jobs...\n",
      "\u001b[33mWARNING\u001b[0m - Number of jobs was specified as 3, but due to only having 1 speakers, MFA will only use 1 jobs.\n",
      "\u001b[32mINFO\u001b[0m - Creating corpus split for feature generation...\n",
      "\u001b[32mINFO\u001b[0m - Generating base features (mfcc)...\n",
      "\u001b[32mINFO\u001b[0m - Generating MFCCs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Calculating CMVN...\n",
      "\u001b[32mINFO\u001b[0m - Creating corpus split with features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Compiling training graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Performing first-pass alignment...\n",
      "\u001b[32mINFO\u001b[0m - Generating alignments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Calculating fMLLR for speaker adaptation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Performing second-pass alignment...\n",
      "\u001b[32mINFO\u001b[0m - Generating alignments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Exporting TextGrids to data/output/public_test_raw...\n",
      "\u001b[32mINFO\u001b[0m - Collecting phone and word alignments from alignment lattices...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00, 22.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m - Finished exporting TextGrids to data/output/public_test_raw!\n",
      "\u001b[32mINFO\u001b[0m - Done! Everything took 26.04665994644165 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/mnt/c/Users/Modern 14/projects/CTA-Zero9-ZAIC2022-Lyric-Alignment/result/jupyter_submission.zip'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predicted_time = []\n",
    "parser = create_parser()\n",
    "args, unknown = parser.parse_known_args([\"align\"])\n",
    "args.dictionary_path =  DICTIONARY_PATH\n",
    "args.acoustic_model_path = ACOUSTIC_MODEL_PATH\n",
    "args.output_directory = PUBLIC_TEST_OUTPUT_RAW\n",
    "\n",
    "for file_name in test_cases:\n",
    "    t1 = time()\n",
    "    separate(os.path.join(SONG_RAW_DIR, file_name), SEPARATED_DATA_DIR)\n",
    "    current_dir_separate = os.path.join(SEPARATED_DATA_DIR, \"mdx_extra_q\", file_name[:-4])\n",
    "    separate_optimized_dir = os.path.join(current_dir_separate, file_name[:-4])\n",
    "    if not os.path.exists(separate_optimized_dir):\n",
    "        os.makedirs(separate_optimized_dir)\n",
    "    os.popen(\"ffmpeg -i {input} -ar 16000 -ac 1 -y {output}\".format(input=os.path.join(current_dir_separate, \"vocals.wav\"), output=os.path.join(separate_optimized_dir, file_name)))\n",
    "    convert_txt(file_name.replace(\"wav\", \"json\"), RAW_LYRIC_JSON, separate_optimized_dir)\n",
    "    args.corpus_directory = separate_optimized_dir\n",
    "    run_align_corpus(args, unknown)\n",
    "    post_process_helper.post_process_json(\n",
    "        file_name=file_name[:-4], \n",
    "        raw_output=PUBLIC_TEST_OUTPUT_RAW, \n",
    "        raw_lyric=RAW_LYRIC_JSON,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "    )\n",
    "    t2 = time()\n",
    "    predicted_time = int(t2*1000 - t1*1000)\n",
    "    all_predicted_time.append((file_name, predicted_time))\n",
    "\n",
    "if not os.path.exists(SUBMISSION_DIR):\n",
    "    os.makedirs(SUBMISSION_DIR)\n",
    "    \n",
    "# Save time submission\n",
    "with open(OUTPUT_TIME_SUBMISSION, 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    fields = [\"fname\", \"time (millisecond)\"] \n",
    "    write.writerow(fields)\n",
    "    write.writerows(all_predicted_time)\n",
    "\n",
    "# Save jupyter submission\n",
    "shutil.make_archive(OUTPUT_JUPYTER_FILE, 'zip', OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('lyric-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cbfeadcb1881f5700240be4d1044f461d803bf2ac08cd4e065f5b04f28c70955"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
